import os
import json
import uuid
import logging
from datetime import datetime
import jieba.analyse
import jieba.posseg as p_seg

from app.utility.base_service import BaseService
from app.utility.base_service import BaseWorld

special_word_list = ["", "+", "|", ":", "ï¼š"]
jieba.setLogLevel(logging.INFO)


class autorun_task(BaseService):
    def __init__(self, services, time_database_id, local_work_path):
        self.log = self.add_service('autorun_task', self)
        self.app = services.get('app_svc')
        self.notionapi = services.get('notionapi_svc')
        self.time_database_id = time_database_id
        self.db_dir = os.path.join(local_work_path, "db")
        self.local_db_path = None
        self.select_uuid_db = {}
        self.N_Algorithm_info = [
            {
                "name": "[1]",
                "db": {},
                "key_generate": lambda _name: _name,
                # "statistics_value_generate": lambda big_value, small_value: str(big_value)+" "+str(small_value),
                "rate": 0.15
            },
            {
                "name": "[2]",
                "db": {},
                "key_generate": lambda _name: self._sort(self._cut(_name)),
                # "statistics_value_generate": lambda big_value, small_value: str(big_value) + " " + str(small_value),
                "rate": 0.3
            },
            {
                "name": "[3]",
                "db": {},
                "key_generate": lambda _name: self._sort(jieba.analyse.extract_tags(_name, 20, allowPOS=['ns', 'n', 'vn', 'v', 'nr'], withFlag=False)),
                # "statistics_value_generate": lambda big_value, small_value: str(big_value) + " " + str(small_value),
                "rate": 0.3
            },
        ]
        self.S_Algorithm_info = [
            {
                "name": "[5]",
                "db": {},
                "key_generate": lambda _name: self._sort(self._filter_cut(_name), False),
                "rate": 0.4
            },
            {
                "name": "[1.1]",
                "db": self.N_Algorithm_info[0]["db"],
                "key_generate": lambda _name: [_name.split(_)[0] for _ in [":", "ï¼š"] if _ in _name][0] if len([_name.split(_)[0] for _ in [":", "ï¼š"] if _ in _name])>0 else "",
                "rate": 0.15
            },
        ]

    async def calculate_cost_time(self):
        """
        è‡ªåŠ¨è®¡ç®—æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•æ•°æ®åº“ä¸­çš„äº‹ä»¶èŠ±è´¹æ—¶é•¿
        :return:
        """
        # è·å–æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•çš„äº‹ä»¶åˆ—è¡¨
        page_size = 20
        sorts = [
            {
                "property": "è‡ªåŠ¨åˆ›å»ºæ—¥æœŸ",
                "direction": "descending"
            }
        ]
        new_pages = await self.notionapi.database_query_page(
            self.time_database_id,
            page_size=page_size + 1,
            sorts=sorts,
            complete_resp=False
        )
        if len(new_pages) <= 1:
            self.log.info("[calculate_cost_time] æ•°æ®é‡ä¸è¶³ï¼Œè·³è¿‡è‡ªåŠ¨è¡¥å…¨è€—æ—¶")
            return

        updated = 0
        # æŸ¥çœ‹å‰page_sizeé¡¹æ˜¯å¦æœ‰æœªå¡«èŠ±è´¹çš„æ—¶é—´çš„äº‹ä»¶ï¼Œè®¡ç®—å¹¶å¡«å…¥èŠ±è´¹çš„æ—¶é—´
        for _index in range(min(page_size, len(new_pages))):
            page = new_pages[_index]
            auto_value = page["properties"]["è®¡ç®—èŠ±è´¹æ—¶é•¿(auto)"]["number"]
            if auto_value is not None:
                continue
            # éœ€è¦è‡³å°‘ä¸‹ä¸€æ¡è®°å½•ä½œä¸ºå‚è€ƒ
            if _index + 1 >= len(new_pages):
                continue
            if not page["properties"]["äº‹ä»¶åç§°"]["title"]:
                continue
            next_page = new_pages[_index + 1]
            current_time = self.convert_ISO_8601(page["properties"]["è‡ªåŠ¨åˆ›å»ºæ—¥æœŸ"]["created_time"])
            previous_time = self.convert_ISO_8601(next_page["properties"]["è‡ªåŠ¨åˆ›å»ºæ—¥æœŸ"]["created_time"])
            delta_minutes = (current_time - previous_time).total_seconds() / 60
            if delta_minutes <= 0:
                self.log.warning(f"[calculate_cost_time] {page['id']} è€—æ—¶è®¡ç®—å¾—åˆ°éæ­£å€¼ {delta_minutes}ï¼Œå·²è·³è¿‡")
                continue
            cost_min_time = round(delta_minutes, 2)
            if cost_min_time > 7 * 24 * 60:
                self.log.warning(f"[calculate_cost_time] {page['id']} è€—æ—¶ç»“æœ {cost_min_time} åˆ†é’Ÿè¿‡å¤§ï¼Œå·²è·³è¿‡")
                continue
            properties = self.notionapi.demo_property_normal("è®¡ç®—èŠ±è´¹æ—¶é•¿(auto)", cost_min_time, "number")
            await self.notionapi.database_update_page(page["id"], properties)
            name = page["properties"]["äº‹ä»¶åç§°"]["title"]
            page_name = name[0]["plain_text"] if name else ""
            self.log.info(f'è®¡ç®—ç”¨æ—¶ {page_name}: {cost_min_time}')
            updated += 1

        if updated == 0:
            self.log.info("[calculate_cost_time] æœ¬æ¬¡æœªå‘ç°éœ€è¦è¡¥å…¨çš„äº‹ä»¶")
        else:
            self.log.info(f"[calculate_cost_time] å·²è¡¥å…¨ {updated} æ¡äº‹ä»¶çš„è€—æ—¶ä¿¡æ¯")

    @staticmethod
    def convert_ISO_8601(raw):
        return datetime.strptime(raw.split(".")[0], '%Y-%m-%dT%H:%M:%S')

    @staticmethod
    def time_event_struct(a=None, b=None, c=None, d=None, e=None, f=None):
        return {
            "äº‹ä»¶åç§°": a,
            "ğŸ™Œé¡ºä¾¿åš": b,
            "ğŸ°å¤§ç±»-ç»´åº¦": c,
            "ğŸ‘£å°ç±»-è¡Œä¸º": d,
            "åˆ›å»ºæ—¶é—´": e,
            "æ±‡æ€»èŠ±è´¹æ—¶é•¿": f
        }

    async def generate_db_path(self):
        """
        ç”Ÿæˆæœ¬å‘¨é‡‡é›†æ•°æ®çš„æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        :return:
        """
        self.log.info("[generate_db_path] å¼€å§‹ç”Ÿæˆæœ¬å‘¨æ•°æ®åº“æ–‡ä»¶ ...")
        print("[generate_db_path] å¼€å§‹ç”Ÿæˆæœ¬å‘¨æ•°æ®åº“æ–‡ä»¶ ...", flush=True)
        # åˆ¤æ–­æœ¬å‘¨æ•°æ®æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
        _judge_list = [_ for _ in BaseWorld.getfile(self.db_dir) if self.local_week().split("(")[0] in _]
        if len(_judge_list) == 0:
            # æ–°å‘¨æ›´æ–°
            self.log.info("[generate_db_path] æœªå‘ç°æœ¬å‘¨æ•°æ®ï¼Œå‡†å¤‡å…¨é‡åŒæ­¥")
            print("[generate_db_path] æœªå‘ç°æœ¬å‘¨æ•°æ®ï¼Œå‡†å¤‡å…¨é‡åŒæ­¥", flush=True)
            self.local_db_path = await self.transfo_training_set()
            self.log.info(f"[+]æ–°å‘¨æ›´æ–°æ•°æ®åº“å®Œæˆ[{self.local_db_path}]")
            print(f"[generate_db_path] æ–°å‘¨æ›´æ–°æ•°æ®åº“å®Œæˆ -> {self.local_db_path}", flush=True)
            # await self.Algorithm_1_generate_db()
        if len(_judge_list) == 1:
            self.local_db_path = [_ for _ in BaseWorld.getfile(self.db_dir) if self.local_week().split("(")[0] in _][0]
            self.log.info(f"[~]åˆ·æ–°æœ¬å‘¨æ•°æ®åº“[{self.local_db_path}]")
            print(f"[generate_db_path] åˆ·æ–°æœ¬å‘¨æ•°æ®åº“ -> {self.local_db_path}", flush=True)
        if len(_judge_list) > 1:
            raise Exception("[!]å¼‚å¸¸ æœ‰å¤šä¸ªåœ¨åŒå‘¨ç”Ÿæˆçš„æ•°æ®åº“æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æ•°æ®")
        await self.Algorithm_db_update()
        print("[generate_db_path] Algorithm_db_update å®Œæˆ", flush=True)

    async def transfo_training_set(self):
        """
        è½¬åŒ–è®­ç»ƒé›†
        :return:
        """
        self.log.info("[transfo_training_set] å¼€å§‹ä» Notion æ‹‰å–åŸå§‹äº‹ä»¶æ•°æ®")
        print("[transfo_training_set] å¼€å§‹ä» Notion æ‹‰å–åŸå§‹äº‹ä»¶æ•°æ®", flush=True)
        # è·å–æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•æ•°æ®åº“ä¸­çš„æ‰€æœ‰äº‹ä»¶
        time_event_db = []
        start_cursor = None
        page_index = 1
        total_count = 0
        while True:
            self.log.info(f"[transfo_training_set] è¯·æ±‚ç¬¬ {page_index} é¡µï¼Œstart_cursor={start_cursor}")
            print(f"[transfo_training_set] è¯·æ±‚ç¬¬ {page_index} é¡µï¼Œstart_cursor={start_cursor}", flush=True)
            raw_pages = await self.notionapi.database_query_page(self.time_database_id, start_cursor=start_cursor, complete_resp=True)
            page_results = raw_pages.get("results", [])
            self.log.info(f"[transfo_training_set] ç¬¬ {page_index} é¡µè¿”å› {len(page_results)} æ¡è®°å½•")
            print(f"[transfo_training_set] ç¬¬ {page_index} é¡µè¿”å› {len(page_results)} æ¡è®°å½•", flush=True)
            # æå–äº‹ä»¶åç§°ã€å¤§ç±»ã€å°ç±»ã€åˆ›å»ºæ—¶é—´ã€èŠ±è´¹æ—¶é•¿
            for page in raw_pages["results"]:
                try:
                    raw_event = self.time_event_struct(
                        page["properties"]["äº‹ä»¶åç§°"]["title"][0]["plain_text"],
                        "" if not page["properties"]["ğŸ™Œé¡ºä¾¿åš"]["rich_text"] else
                        page["properties"]["ğŸ™Œé¡ºä¾¿åš"]["rich_text"][0]["plain_text"],
                        page["properties"]["ğŸ°å¤§ç±»-ç»´åº¦"]["select"],
                        page["properties"]["ğŸ‘£å°ç±»-è¡Œä¸º"]["select"],
                        page["properties"]["åˆ›å»ºæ—¶é—´"]["formula"]["string"],
                        page["properties"]["æ±‡æ€»èŠ±è´¹æ—¶é•¿"]["formula"]["number"],
                    )
                except Exception as E:
                    # print(page)
                    continue
                # å»é™¤ä¸å®Œæ•´çš„äº‹ä»¶
                if len([_ for _ in raw_event.values() if _ is None]) > 0:
                    # print(raw_event.values())
                    continue
                time_event_db.append(raw_event)
                total_count += 1
                self.log.info(f"[transfo_training_set] å·²ç´¯è®¡ {total_count} æ¡ï¼Œå½“å‰äº‹ä»¶ï¼š{raw_event}")
                print(f"[transfo_training_set] å·²ç´¯è®¡ {total_count} æ¡ï¼Œå½“å‰äº‹ä»¶ï¼š{raw_event}", flush=True)
            if "has_more" not in raw_pages:
                raise Exception("[!]miss has_more")
            if not raw_pages["has_more"]:
                self.log.info("[transfo_training_set] has_more=Falseï¼Œæ•°æ®æŠ“å–ç»“æŸ")
                print("[transfo_training_set] has_more=Falseï¼Œæ•°æ®æŠ“å–ç»“æŸ", flush=True)
                break
            else:
                start_cursor = raw_pages["next_cursor"]
                page_index += 1
        raw_db = json.dumps(time_event_db, indent=4, ensure_ascii=False)
        db_path = os.path.join(self.db_dir, "{}_{}.json".format(self.local_week(), uuid.uuid4().__str__()))
        with open(db_path, "w", encoding="utf-8") as f:
            # print(len(raw_db))
            self.log.info(f"[+]æ•°æ®åº“é‡‡é›†å®Œæˆï¼Œå†™å…¥ä¸­ï¼š{self.local_db_path}")
            f.write(raw_db)
            self.log.info(f"[+]æ•°æ®åº“å†™å…¥å®Œæˆï¼š{self.local_db_path}")
        self.log.info(f"[transfo_training_set] å…±å†™å…¥ {total_count} æ¡è®°å½•åˆ° {db_path}")
        print(f"[transfo_training_set] å…±å†™å…¥ {total_count} æ¡è®°å½•åˆ° {db_path}", flush=True)
        return db_path

    @staticmethod
    def local_week():
        return str(datetime.now().strftime('%Y-%W(%m-%d)'))

    # async def generate_training_model(self):
    #     """
    #     ç”Ÿæˆæœºå™¨å­¦ä¹ æ¨¡å‹
    #     :return:
    #     """
    #     await self.generate_db_path()
    #     # è¯»å–æœ¬å‘¨æ•°æ®ï¼Œå¹¶è½¬åŒ–ä¸ºpandasæ ¼å¼
    #     with open(self.local_db_path, 'r', encoding="utf-8") as f:
    #         raw_db = f.read()
    #         json_db = json.loads(raw_db)
    #         panda_db = pandas.json_normalize(json_db)
    #         print(panda_db.groupby("äº‹ä»¶åç§°").size())

    async def update_notion_select(self, page_id, small_OR_big, _uuid, page_name):
        """
        æ›´æ–°notioné¡µé¢çš„å¤§ç±»å°ç±»æ ‡ç­¾
        :param page_id:
        :param small_OR_big:
        :param _uuid:
        :param page_name:
        :return:
        """
        if small_OR_big == 0:
            small_OR_big = "ğŸ‘£å°ç±»-è¡Œä¸º"
        elif small_OR_big == 1:
            small_OR_big = "ğŸ°å¤§ç±»-ç»´åº¦"
        else:
            raise Exception("[!]update_notion_select()æœªè¾“å…¥æœ‰æ•ˆçš„å¤§ç±»å°ç±»")

        # å¡«å…¥æ ‡ç­¾é€‰é¡¹
        self.log.info(f"æ›´æ–°[{page_name}]çš„[{small_OR_big}]æ ‡ç­¾:{self.select_uuid_db[_uuid]}")
        properties = self.notionapi.demo_property_normal(small_OR_big, {"id": _uuid}, "select")
        await self.notionapi.database_update_page(page_id, properties)

    async def update_notion_autolog(self, page_id, Algorithm_name, rate, page_name):
        """
        æ›´æ–°notioné¡µé¢çš„è‡ªåŠ¨åŒ–è®°å½•
        :param page_id:
        :param Algorithm_name:
        :param rate:
        :param page_name:
        :return:
        """
        content = "{}ï¼š{}".format(Algorithm_name, rate)
        if content == "+ï¼š+":
            # self.log.info(f"æŸ¥ä¸åˆ°[{page_name}]")
            return
        self.log.info(f"æ›´æ–°[{page_name}]çš„[ğŸ¤–è‡ªåŠ¨åŒ–è®°å½•]:{content}")
        properties = self.notionapi.demo_property_text("rich_text", "ğŸ¤–è‡ªåŠ¨åŒ–è®°å½•", content)
        await self.notionapi.database_update_page(page_id, properties)

    async def Algorithm_generate_db1(self, _generate):
        """
        å®Œå…¨åŒ¹é…çš„åœºæ™¯:ç»Ÿè®¡â€œäº‹ä»¶åç§°â€çš„æ¯”ç‡ç»Ÿè®¡
        :return:
        """
        Algorithm_statistics_db = self.Algorithm_generate_statistics_db(
            self.local_db_path,
            _generate,
            lambda big_value, small_value: str(big_value)+" "+str(small_value),
        )
        return self.Algorithm_generate_rate_db(Algorithm_statistics_db)

    async def Algorithm_generate_db2(self, _generate):
        """

        :param _generate:
        :return:
        """
        big_Algorithm_statistics_db = self.Algorithm_generate_statistics_db(
            self.local_db_path,
            _generate,
            lambda big_value, small_value: str(big_value),
        )
        small_Algorithm_statistics_db = self.Algorithm_generate_statistics_db(
            self.local_db_path,
            _generate,
            lambda big_value, small_value: str(small_value),
        )
        big_Algorithm_db = self.Algorithm_generate_rate_db(big_Algorithm_statistics_db)
        small_Algorithm_db = self.Algorithm_generate_rate_db(small_Algorithm_statistics_db)
        # print(json.dumps(big_Algorithm_db, indent=4, ensure_ascii=False))
        # print(json.dumps(small_Algorithm_db, indent=4, ensure_ascii=False))
        return {"big": big_Algorithm_db, "small": small_Algorithm_db}

    def Algorithm_generate_statistics_db(self, local_db_path, key_generate, value_generate):
        with open(local_db_path, 'r', encoding="utf-8") as f:
            _db = {}
            raw_db = f.read()
            json_db = json.loads(raw_db)
            for _cell in json_db:
                # æå–å¤§ç±»å°ç±»çš„uuidä¸å€¼
                for _ in ["ğŸ°å¤§ç±»-ç»´åº¦", "ğŸ‘£å°ç±»-è¡Œä¸º"]:
                    select_uuid = _cell[_]["id"]
                    select_name = _cell[_]["name"]
                    if select_uuid not in self.select_uuid_db:
                        self.select_uuid_db.update({select_uuid: select_name})
                # è¯†åˆ«ä¼ å…¥
                _key = key_generate(_cell["äº‹ä»¶åç§°"])
                if type(_key) is str:
                    db_cell_name_list = [_key]
                elif type(_key) is list:
                    db_cell_name_list = _key
                else:
                    raise Exception("[!]Algorithm_generate_statistics_db()æ–¹æ³•ä¼ å…¥äº†å¥‡æ€ªçš„ç”Ÿæˆå™¨å’Œåå­—æ•°æ®ï¼Œç”Ÿæˆçš„ç±»å‹ï¼š"+str(type(key_generate(_cell["äº‹ä»¶åç§°"]))))
                for range_index in range(len(db_cell_name_list)):
                    _uuid = value_generate(str(_cell["ğŸ°å¤§ç±»-ç»´åº¦"]["id"]), str(_cell["ğŸ‘£å°ç±»-è¡Œä¸º"]["id"]))
                    if db_cell_name_list[range_index] in _db:
                        if _uuid in _db[db_cell_name_list[range_index]]:
                            _db[db_cell_name_list[range_index]][_uuid] += 1
                        else:
                            _db[db_cell_name_list[range_index]].update({_uuid: 1})
                    else:
                        _db.update({db_cell_name_list[range_index]: {_uuid: 1}})
            return _db

    @staticmethod
    def Algorithm_generate_rate_db(_statistics_db):
        """
        ç”Ÿæˆå¸¦æ¯”ç‡çš„æ•°æ®åº“ï¼Œæ•°æ®åº“ç»“æ„ï¼šæœ€é«˜æ•°é‡å€¼çš„uuidï¼Œ æœ€é«˜æ•°é‡å€¼uuidçš„æ¯”ç‡ï¼Œ æœ€é«˜æ•°é‡å€¼uuidçš„çš„æ•°é‡å€¼ï¼Œ æ‰€æœ‰uuidçš„æ•°é‡å€¼æ€»å’Œ
        :param _statistics_db:
        :return:
        """
        Algorithm_db = {}
        for _key, _value in _statistics_db.items():
            # åˆ¤æ–­ç©ºå€¼æˆ–æ— æ„ä¹‰è¯
            if _key in ["", [], None, "['']"]:
                continue
            # ç»Ÿè®¡è¯¥å­—æ®µæ‰€æœ‰uuidçš„æ•°é‡å€¼
            all_num = 0
            # è®°å½•uuidä¸­æœ€é«˜çš„æ•°é‡å€¼
            _max_num = 0
            # è®°å½•æœ€é«˜æ•°é‡å€¼çš„uuid
            _max_uuid = None
            for _uuid, _uuid_num in _value.items():
                all_num = all_num + _uuid_num
                if _uuid_num > _max_num:
                    _max_num = _uuid_num
                    _max_uuid = _uuid
            if all_num <= 2:
                continue
            # æ›´æ–°æ•°æ®åº“: æœ€é«˜æ•°é‡å€¼çš„uuidï¼Œ æœ€é«˜æ•°é‡å€¼uuidçš„æ¯”ç‡ï¼Œ æœ€é«˜æ•°é‡å€¼uuidçš„çš„æ•°é‡å€¼ï¼Œ æ‰€æœ‰uuidçš„æ•°é‡å€¼æ€»å’Œ
            Algorithm_db.update({_key: [_max_uuid, _max_num / all_num, _max_num, all_num, _key]})
        return Algorithm_db

    async def Algorithm_db_update(self):
        # Normalç®—æ³•æ›´æ–°æ•°æ®åº“
        for _ in self.N_Algorithm_info:
            _["db"] = await self.Algorithm_generate_db1(_["key_generate"])
        # ä½¿ç”¨ç®—æ³•1çš„æ’ä»¶1.1,æ›´æ–°ç®—æ³•1æ•°æ®åº“
        _db = await self.Algorithm_generate_db1(self.S_Algorithm_info[1]["key_generate"])
        self.N_Algorithm_info[0]["db"].update(_db)
        # æ›´æ–°ç®—æ³•5
        self.S_Algorithm_info[0]["db"] = await self.Algorithm_generate_db2(self.S_Algorithm_info[0]["key_generate"])

    async def Algorithm_run(self):
        """
        å®Œå…¨åŒ¹é…çš„åœºæ™¯:ç»Ÿè®¡â€œäº‹ä»¶åç§°â€çš„è¿è¡Œ
        :return:
        """
        # è·å–æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•çš„äº‹ä»¶åˆ—è¡¨ï¼Œè·å–æœªæ ‡è®°æ ‡ç­¾çš„äº‹ä»¶
        page_size = 20
        _filter = {
            "and": [
                {
                    "or": [
                        {
                            "property": "ğŸ°å¤§ç±»-ç»´åº¦",
                            "select": {
                                "is_empty": True
                            }
                        },
                        {
                            "property": "ğŸ‘£å°ç±»-è¡Œä¸º",
                            "select": {
                                "is_empty": True
                            }
                        },
                    ],
                },
                {
                    "property": "ğŸ¤–è‡ªåŠ¨åŒ–è®°å½•",
                    "rich_text": {
                        "is_empty": True
                    }
                },
            ]
        }
        new_pages = await self.notionapi.database_query_page(self.time_database_id, _filter=_filter, page_size=page_size)
        # æŸ¥çœ‹å‰10é¡¹æ˜¯å¦æœ‰æœªå¡«èŠ±è´¹çš„æ—¶é—´çš„äº‹ä»¶ï¼Œè®¡ç®—å¹¶å¡«å…¥èŠ±è´¹çš„æ—¶é—´
        for _index in range(len(new_pages)):
            if not new_pages[_index]["properties"]["äº‹ä»¶åç§°"]["title"]:
                continue
            page_name = new_pages[_index]["properties"]["äº‹ä»¶åç§°"]["title"][0]["plain_text"]
            N_flag = False
            for _ in self.N_Algorithm_info:
                compare_data = _["key_generate"](page_name)
                # æ ¹æ®äº‹ä»¶åç§°åœ¨æ•°æ®åº“ä¸­è¿›è¡ŒåŒ¹é…
                if compare_data in _["db"] and _["db"][compare_data][1] > _["rate"]:
                    # æ›´æ–°å‘½ä¸­çš„åŒ¹é…ç»“æœåˆ°notionä¸­
                    _uuid_list = _["db"][compare_data][0].split(" ")
                    # å¡«å…¥æ ‡ç­¾é€‰é¡¹
                    await self.update_notion_select(new_pages[_index]["id"], 1, _uuid_list[0], page_name)
                    await self.update_notion_select(new_pages[_index]["id"], 0, _uuid_list[1], page_name)
                    # å¡«å…¥è‡ªåŠ¨åŒ–è®°å½•
                    await self.update_notion_autolog(new_pages[_index]["id"], _["name"], "%.2f"%float(_["db"][compare_data][1]), page_name)
                    N_flag = True
                    break
            # ç®—æ³•5
            if not N_flag:
                big_log = await self.Algorithm_1_extend_1_run(page_name, new_pages[_index]["id"])
                small_log = await self.Algorithm_5_extend_1_run(page_name, new_pages[_index]["id"], "small")
                if not big_log:
                    big_uuid, big_log = await self.Algorithm_5_run(page_name, "big")
                    if big_uuid:
                        await self.update_notion_select(new_pages[_index]["id"], 1, big_uuid, page_name)
                if not small_log:
                    small_uuid, small_log = await self.Algorithm_5_run(page_name, "small")
                    if small_uuid:
                        await self.update_notion_select(new_pages[_index]["id"], 0, small_uuid, page_name)
                if small_log or big_log:
                    await self.update_notion_autolog(new_pages[_index]["id"], f"{big_log[0]}+{small_log[0]}", f"{big_log[1]}+{small_log[1]}", page_name)

    async def Algorithm_1_extend_1_run(self, page_name, page_id):
        """
        ç®—æ³•1çš„æ‰©å±•ç®—æ³•ï¼Œè¯†åˆ«äº‹ä»¶åç§°æ˜¯å¦æœ‰å†’å·çš„ç‰¹æ®Šå­—ç¬¦è¿›è¡Œåˆ‡å‰²ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºå¤§ç±»çš„åˆ¤åˆ«å…ƒç´ ï¼Œå¹¶åœ¨ç®—æ³•1æ•°æ®åº“ä¸­å¯»æ‰¾ç»“æœ
        :param page_name:
        :param page_id:
        :return:
        """
        split_words = [_ for _ in [":", "ï¼š"] if _ in page_name]
        if len(split_words) > 0:
            page_name_0 = page_name.split(split_words[0])[0]
            Algorithm_1 = self.N_Algorithm_info[0]
            if page_name_0 in Algorithm_1["db"] and Algorithm_1["db"][page_name_0][1] > Algorithm_1["rate"]:
                _uuid_0 = Algorithm_1["db"][page_name_0][0].split(" ")[0]
                await self.update_notion_select(page_id, 1, _uuid_0, page_name)
                return [f"[1.1](big)", f"{page_name_0} {'%.2f'%float(Algorithm_1['db'][page_name_0][1])}"]
        return ["", ""]

    async def Algorithm_5_extend_1_run(self, page_name, page_id, _type):
        """
        ç®—æ³•1çš„æ‰©å±•ç®—æ³•ï¼Œè¯†åˆ«äº‹ä»¶åç§°æ˜¯å¦æœ‰å†’å·çš„ç‰¹æ®Šå­—ç¬¦è¿›è¡Œåˆ‡å‰²ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºå¤§ç±»çš„åˆ¤åˆ«å…ƒç´ ï¼Œå¹¶åœ¨ç®—æ³•1æ•°æ®åº“ä¸­å¯»æ‰¾ç»“æœ
        :param page_name:
        :param page_id:
        :param _type:
        :return:
        """
        split_words = [_ for _ in [":", "ï¼š"] if _ in page_name]
        if len(split_words) > 0:
            page_name_1 = page_name.split(split_words[0])[1]
            max_uuid, _log = await self.Algorithm_5_run(page_name_1, _type)
            if max_uuid:
                await self.update_notion_select(page_id, 0, max_uuid, page_name)
                _log[0] = f"[5.1]({_type})"
                return _log
        return ["", ""]

    async def Algorithm_5_run(self, page_name, _type):
        # åˆ†è¯
        Algorithm_5 = self.S_Algorithm_info[0]
        words_list = Algorithm_5["key_generate"](page_name)
        hit_list = []
        for word in words_list:
            if word in Algorithm_5["db"][_type] and Algorithm_5["db"][_type][word][1] >= Algorithm_5["rate"]:
                hit_list.append(Algorithm_5["db"][_type][word])
        max_uuid = None
        max_num = 0
        max_key = None
        for _ in hit_list:
            if _[2] > max_num:
                max_num = _[2]
                max_uuid = _[0]
                max_key = _[-1]
        if max_uuid:
            return max_uuid, [f"{Algorithm_5['name']}({_type})", f"{max_key} {str(max_num)}"]
        return "", ["", ""]

    @staticmethod
    def _sort(_list, _str=True):
        list(set(_list)).sort()
        if _str:
            return _list.__str__()
        else:
            return _list

    @staticmethod
    def _filter_cut(sentence):
        # è¿‡æ»¤ä¸éœ€è¦çš„è¯æ€§ï¼š
        # åŠ©è¯+è¿è¯
        special_word_property = ["u", "ud", "ug", "uj", "ul", "uv", "uz", "c"]
        #
        _data = []
        [_data.append(_.word) for _ in p_seg.cut(sentence) if _.word.strip() not in special_word_list and _.flag not in special_word_property]
        return _data

    @staticmethod
    def _cut(sentence, withFlag=False):
        if not withFlag:
            _data = []
            [_data.append(_.word) for _ in p_seg.cut(sentence) if _.word.strip() not in special_word_list]
        else:
            _data = {}
            [_data.update({_.word: _.flag}) for _ in p_seg.cut(sentence) if _.word.strip() not in special_word_list]
        return _data

    async def run(self):
        scheduler = self.app.get_scheduler()
        await self.generate_db_path()
        await self.Algorithm_run()
        await self.calculate_cost_time()
        scheduler.add_job(self.calculate_cost_time, 'interval', seconds=600)
        scheduler.add_job(self.Algorithm_run, 'interval', seconds=600)
        scheduler.add_job(self.generate_db_path, 'interval', seconds=60*24)
        # scheduler.add_job(self.generate_db_path, 'cron', day_of_week='mon,tue,thu,sat', hour=4)


if __name__ == '__main__':
    pass
