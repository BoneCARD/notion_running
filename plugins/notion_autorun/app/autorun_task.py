import os
import json
import uuid
import logging
from datetime import datetime
import jieba.analyse
import jieba.posseg as p_seg

from app.utility.base_service import BaseService
from app.utility.base_service import BaseWorld

special_word_list = ["", "+", "|", ":", "ï¼š"]
jieba.setLogLevel(logging.INFO)


class autorun_task(BaseService):
    def __init__(self, services, time_database_id, local_work_path):
        self.log = self.add_service('autorun_task', self)
        self.app = services.get('app_svc')
        self.notionapi = services.get('notionapi_svc')
        self.time_database_id = time_database_id
        self.db_dir = os.path.join(local_work_path, "db")
        self.local_db_path = None
        self.select_uuid_db = {}
        self.N_Algorithm_info = [
            {
                "name": "[1]",
                "db": None,
                "key_generate": lambda _name: _name,
                # "statistics_value_generate": lambda big_value, small_value: str(big_value)+" "+str(small_value),
                "rate": 0.15
            },
            {
                "name": "[2]",
                "db": None,
                "key_generate": lambda _name: self._sort(self._cut(_name)),
                # "statistics_value_generate": lambda big_value, small_value: str(big_value) + " " + str(small_value),
                "rate": 0.3
            },
            {
                "name": "[3]",
                "db": None,
                "key_generate": lambda _name: self._sort(jieba.analyse.extract_tags(_name, 20, allowPOS=['ns', 'n', 'vn', 'v', 'nr'], withFlag=False)),
                # "statistics_value_generate": lambda big_value, small_value: str(big_value) + " " + str(small_value),
                "rate": 0.3
            },
        ]
        self.S_Algorithm_info = [
            {
                "name": "[5]",
                "db": None,
                "key_generate": lambda _name: self._sort(self._cut(_name), False),
                "rate": 0.4
            },
        ]

    async def calculate_cost_time(self):
        """
        è‡ªåŠ¨è®¡ç®—æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•æ•°æ®åº“ä¸­çš„äº‹ä»¶èŠ±è´¹æ—¶é•¿
        :return:
        """
        # èŽ·å–æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•çš„äº‹ä»¶åˆ—è¡¨
        page_size = 10
        new_pages = await self.notionapi.database_query_page(self.time_database_id, page_size=page_size + 1)
        # æŸ¥çœ‹å‰10é¡¹æ˜¯å¦æœ‰æœªå¡«èŠ±è´¹çš„æ—¶é—´çš„äº‹ä»¶ï¼Œè®¡ç®—å¹¶å¡«å…¥èŠ±è´¹çš„æ—¶é—´
        for _index in range(page_size):
            if not new_pages[_index]["properties"]["æ±‡æ€»èŠ±è´¹æ—¶é•¿"]["formula"]["number"]:
                # è®¡ç®—èŠ±è´¹æ—¶é•¿
                cost_min_time = (self.convert_ISO_8601(
                    new_pages[_index]["properties"]["è‡ªåŠ¨åˆ›å»ºæ—¥æœŸ"]["created_time"]) - self.convert_ISO_8601(
                    new_pages[_index + 1]["properties"]["è‡ªåŠ¨åˆ›å»ºæ—¥æœŸ"]["created_time"])).seconds / 60
                # å¡«å…¥èŠ±è´¹æ—¶é•¿
                properties = self.notionapi.demo_property_normal("è®¡ç®—èŠ±è´¹æ—¶é•¿(auto)", cost_min_time, "number")
                await self.notionapi.database_update_page(new_pages[_index]["id"], properties)
                self.log.info(f'è®¡ç®—ç”¨æ—¶ {new_pages[_index]["properties"]["äº‹ä»¶åç§°"]["title"][0]["plain_text"] + ":" + cost_min_time.__str__()}')

    @staticmethod
    def convert_ISO_8601(raw):
        return datetime.strptime(raw.split(".")[0], '%Y-%m-%dT%H:%M:%S')

    @staticmethod
    def time_event_struct(a=None, b=None, c=None, d=None, e=None, f=None):
        return {
            "äº‹ä»¶åç§°": a,
            "é¡ºä¾¿åš": b,
            "ðŸŽ°å¤§ç±»-ç»´åº¦": c,
            "ðŸ‘£å°ç±»è¡Œä¸º": d,
            "åˆ›å»ºæ—¶é—´": e,
            "æ±‡æ€»èŠ±è´¹æ—¶é•¿": f
        }

    async def generate_db_path(self):
        """
        ç”Ÿæˆæœ¬å‘¨é‡‡é›†æ•°æ®çš„æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        :return:
        """
        # åˆ¤æ–­æœ¬å‘¨æ•°æ®æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
        _judge_list = [_ for _ in BaseWorld.getfile(self.db_dir) if self.local_week().split("(")[0] in _]
        if len(_judge_list) == 0:
            # æ–°å‘¨æ›´æ–°
            self.local_db_path = await self.transfo_training_set()
            # await self.Algorithm_1_generate_db()
        if len(_judge_list) == 1:
            self.local_db_path = [_ for _ in BaseWorld.getfile(self.db_dir) if self.local_week().split("(")[0] in _][0]
        if len(_judge_list) > 1:
            raise Exception("[!]å¼‚å¸¸ æœ‰å¤šä¸ªåœ¨åŒå‘¨ç”Ÿæˆçš„æ•°æ®åº“æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æ•°æ®")
        await self.Algorithm_db_update()

    async def transfo_training_set(self):
        """
        è½¬åŒ–è®­ç»ƒé›†
        :return:
        """
        # èŽ·å–æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•æ•°æ®åº“ä¸­çš„æ‰€æœ‰äº‹ä»¶
        time_event_db = []
        start_cursor = None
        while True:
            raw_pages = await self.notionapi.database_query_page(self.time_database_id, start_cursor=start_cursor, complete_resp=True)
            # æå–äº‹ä»¶åç§°ã€å¤§ç±»ã€å°ç±»ã€åˆ›å»ºæ—¶é—´ã€èŠ±è´¹æ—¶é•¿
            for page in raw_pages["results"]:
                raw_event = self.time_event_struct(
                    page["properties"]["äº‹ä»¶åç§°"]["title"][0]["plain_text"],
                    "" if not page["properties"]["é¡ºä¾¿åš"]["rich_text"] else page["properties"]["é¡ºä¾¿åš"]["rich_text"][0][
                        "plain_text"],
                    page["properties"]["ðŸŽ°å¤§ç±»-ç»´åº¦"]["select"],
                    page["properties"]["ðŸ‘£å°ç±»è¡Œä¸º"]["select"],
                    page["properties"]["åˆ›å»ºæ—¶é—´"]["formula"]["string"],
                    page["properties"]["æ±‡æ€»èŠ±è´¹æ—¶é•¿"]["formula"]["number"],
                )
                # åŽ»é™¤ä¸å®Œæ•´çš„äº‹ä»¶
                if len([_ for _ in raw_event.values() if _ is None]) > 0:
                    # print(raw_event.values())
                    continue
                time_event_db.append(raw_event)
            if "has_more" not in raw_pages:
                raise Exception("[!]miss has_more")
            if not raw_pages["has_more"]:
                break
            else:
                start_cursor = raw_pages["next_cursor"]
        raw_db = json.dumps(time_event_db, indent=4, ensure_ascii=False)
        db_path = os.path.join(self.db_dir, "{}_{}.json".format(self.local_week(), uuid.uuid4().__str__()))
        with open(db_path, "w", encoding="utf-8") as f:
            # print(len(raw_db))
            f.write(raw_db)
        return db_path

    @staticmethod
    def local_week():
        return str(datetime.now().strftime('%Y-%W(%m-%d)'))

    # async def generate_training_model(self):
    #     """
    #     ç”Ÿæˆæœºå™¨å­¦ä¹ æ¨¡åž‹
    #     :return:
    #     """
    #     await self.generate_db_path()
    #     # è¯»å–æœ¬å‘¨æ•°æ®ï¼Œå¹¶è½¬åŒ–ä¸ºpandasæ ¼å¼
    #     with open(self.local_db_path, 'r', encoding="utf-8") as f:
    #         raw_db = f.read()
    #         json_db = json.loads(raw_db)
    #         panda_db = pandas.json_normalize(json_db)
    #         print(panda_db.groupby("äº‹ä»¶åç§°").size())

    async def update_notion_select(self, page_id, small_OR_big, _uuid, page_name):
        """
        æ›´æ–°notioné¡µé¢çš„å¤§ç±»å°ç±»æ ‡ç­¾
        :param page_id:
        :param small_OR_big:
        :param _uuid:
        :param page_name:
        :return:
        """
        if small_OR_big == 0:
            small_OR_big = "ðŸ‘£å°ç±»è¡Œä¸º"
        elif small_OR_big == 1:
            small_OR_big = "ðŸŽ°å¤§ç±»-ç»´åº¦"
        else:
            raise Exception("[!]update_notion_select()æœªè¾“å…¥æœ‰æ•ˆçš„å¤§ç±»å°ç±»")

        # å¡«å…¥æ ‡ç­¾é€‰é¡¹
        self.log.info(f"æ›´æ–°[{page_name}]çš„[{small_OR_big}]æ ‡ç­¾:{self.select_uuid_db[_uuid]}")
        properties = self.notionapi.demo_property_normal(small_OR_big, {"id": _uuid}, "select")
        await self.notionapi.database_update_page(page_id, properties)

    async def update_notion_autolog(self, page_id, Algorithm_name, rate, page_name):
        """
        æ›´æ–°notioné¡µé¢çš„è‡ªåŠ¨åŒ–è®°å½•
        :param page_id:
        :param Algorithm_name:
        :param rate:
        :param page_name:
        :return:
        """
        content = "{}ï¼š{}".format(Algorithm_name, rate)
        self.log.info(f"æ›´æ–°[{page_name}]çš„[è‡ªåŠ¨åŒ–è®°å½•]:{content}")
        properties = self.notionapi.demo_property_text("rich_text", "è‡ªåŠ¨åŒ–è®°å½•", content)
        await self.notionapi.database_update_page(page_id, properties)

    async def Algorithm_generate_db1(self, _generate):
        """
        å®Œå…¨åŒ¹é…çš„åœºæ™¯:ç»Ÿè®¡â€œäº‹ä»¶åç§°â€çš„æ¯”çŽ‡ç»Ÿè®¡
        :return:
        """
        Algorithm_statistics_db = self.Algorithm_generate_statistics_db(
            self.local_db_path,
            _generate,
            lambda big_value, small_value: str(big_value)+" "+str(small_value),
        )
        return self.Algorithm_generate_rate_db(Algorithm_statistics_db)

    async def Algorithm_generate_db2(self, _generate):
        """

        :param _generate:
        :return:
        """
        big_Algorithm_statistics_db = self.Algorithm_generate_statistics_db(
            self.local_db_path, _generate,
            lambda big_value, small_value: str(big_value),
        )
        small_Algorithm_statistics_db = self.Algorithm_generate_statistics_db(
            self.local_db_path, _generate,
            lambda big_value, small_value: str(small_value),
        )
        big_Algorithm_db = self.Algorithm_generate_rate_db(big_Algorithm_statistics_db)
        small_Algorithm_db = self.Algorithm_generate_rate_db(small_Algorithm_statistics_db)
        # print(json.dumps(big_Algorithm_db, indent=4, ensure_ascii=False))
        # print(json.dumps(small_Algorithm_db, indent=4, ensure_ascii=False))
        return {"big": big_Algorithm_db, "small": small_Algorithm_db}

    def Algorithm_generate_statistics_db(self, local_db_path, key_generate, value_generate):
        with open(local_db_path, 'r', encoding="utf-8") as f:
            _db = {}
            raw_db = f.read()
            json_db = json.loads(raw_db)
            for _cell in json_db:
                # æå–å¤§ç±»å°ç±»çš„uuidä¸Žå€¼
                for _ in ["ðŸŽ°å¤§ç±»-ç»´åº¦", "ðŸ‘£å°ç±»è¡Œä¸º"]:
                    select_uuid = _cell[_]["id"]
                    select_name = _cell[_]["name"]
                    if select_uuid not in self.select_uuid_db:
                        self.select_uuid_db.update({select_uuid: select_name})
                # è¯†åˆ«ä¼ å…¥
                _key = key_generate(_cell["äº‹ä»¶åç§°"])
                if type(_key) is str:
                    db_cell_name_list = [_key]
                elif type(_key) is list:
                    db_cell_name_list = _key
                else:
                    raise Exception("[!]Algorithm_generate_statistics_db()æ–¹æ³•ä¼ å…¥äº†å¥‡æ€ªçš„ç”Ÿæˆå™¨å’Œåå­—æ•°æ®ï¼Œç”Ÿæˆçš„ç±»åž‹ï¼š"+str(type(key_generate(_cell["äº‹ä»¶åç§°"]))))
                for range_index in range(len(db_cell_name_list)):
                    _uuid = value_generate(str(_cell["ðŸŽ°å¤§ç±»-ç»´åº¦"]["id"]), str(_cell["ðŸ‘£å°ç±»è¡Œä¸º"]["id"]))
                    if db_cell_name_list[range_index] in _db:
                        if _uuid in _db[db_cell_name_list[range_index]]:
                            _db[db_cell_name_list[range_index]][_uuid] += 1
                        else:
                            _db[db_cell_name_list[range_index]].update({_uuid: 1})
                    else:
                        _db.update({db_cell_name_list[range_index]: {_uuid: 1}})
            return _db

    @staticmethod
    def Algorithm_generate_rate_db(_statistics_db):
        Algorithm_db = {}
        for _key, _value in _statistics_db.items():
            # ç»Ÿè®¡è¯¥å­—æ®µæ‰€æœ‰uuidçš„æ•°é‡å€¼
            all_num = 0
            # è®°å½•uuidä¸­æœ€é«˜çš„æ•°é‡å€¼
            _max_num = 0
            # è®°å½•æœ€é«˜æ•°é‡å€¼çš„uuid
            _max_uuid = None
            for _uuid, _uuid_num in _value.items():
                all_num = all_num + _uuid_num
                if _uuid_num > _max_num:
                    _max_num = _uuid_num
                    _max_uuid = _uuid
            if all_num <= 2:
                continue
            # æ›´æ–°æ•°æ®åº“: æœ€é«˜æ•°é‡å€¼çš„uuidï¼Œ æœ€é«˜æ•°é‡å€¼uuidçš„æ¯”çŽ‡ï¼Œ æœ€é«˜æ•°é‡å€¼uuidçš„çš„æ•°é‡å€¼ï¼Œ æ‰€æœ‰uuidçš„æ•°é‡å€¼æ€»å’Œ
            Algorithm_db.update({_key: [_max_uuid, _max_num / all_num, _max_num, all_num, _key]})
        return Algorithm_db

    async def Algorithm_db_update(self):
        for _ in self.N_Algorithm_info:
            _["db"] = await self.Algorithm_generate_db1(_["key_generate"])
        self.S_Algorithm_info[0]["db"] = await self.Algorithm_generate_db2(self.S_Algorithm_info[0]["key_generate"])

    async def Algorithm_run(self):
        """
        å®Œå…¨åŒ¹é…çš„åœºæ™¯:ç»Ÿè®¡â€œäº‹ä»¶åç§°â€çš„è¿è¡Œ
        :return:
        """
        # èŽ·å–æŸ³æ¯”æ­‡å¤«æ—¶é—´ç»Ÿè®¡æ³•çš„äº‹ä»¶åˆ—è¡¨ï¼ŒèŽ·å–æœªæ ‡è®°æ ‡ç­¾çš„äº‹ä»¶
        page_size = 20
        _filter = {
            "and": [
                {
                    "or": [
                        {
                            "property": "ðŸŽ°å¤§ç±»-ç»´åº¦",
                            "select": {
                                "is_empty": True
                            }
                        },
                        {
                            "property": "ðŸ‘£å°ç±»è¡Œä¸º",
                            "select": {
                                "is_empty": True
                            }
                        },
                    ],
                },
                {
                    "property": "è‡ªåŠ¨åŒ–è®°å½•",
                    "rich_text": {
                        "is_empty": True
                    }
                },
            ]
        }
        new_pages = await self.notionapi.database_query_page(self.time_database_id, _filter=_filter, page_size=page_size)
        # æŸ¥çœ‹å‰10é¡¹æ˜¯å¦æœ‰æœªå¡«èŠ±è´¹çš„æ—¶é—´çš„äº‹ä»¶ï¼Œè®¡ç®—å¹¶å¡«å…¥èŠ±è´¹çš„æ—¶é—´
        for _index in range(len(new_pages)):
            page_name = new_pages[_index]["properties"]["äº‹ä»¶åç§°"]["title"][0]["plain_text"]
            N_flag = False
            for _ in self.N_Algorithm_info:
                compare_data = _["key_generate"](page_name)
                # æ ¹æ®äº‹ä»¶åç§°åœ¨æ•°æ®åº“ä¸­è¿›è¡ŒåŒ¹é…
                if compare_data in _["db"] and _["db"][compare_data][1] > _["rate"]:
                    # æ›´æ–°å‘½ä¸­çš„åŒ¹é…ç»“æžœåˆ°notionä¸­
                    _uuid_list = _["db"][compare_data][0].split(" ")
                    # å¡«å…¥æ ‡ç­¾é€‰é¡¹
                    await self.update_notion_select(new_pages[_index]["id"], 1, _uuid_list[0], page_name)
                    await self.update_notion_select(new_pages[_index]["id"], 0, _uuid_list[1], page_name)
                    # å¡«å…¥è‡ªåŠ¨åŒ–è®°å½•
                    await self.update_notion_autolog(new_pages[_index]["id"], _["name"], "%.2f"%float(_["db"][compare_data][1]), page_name)
                    N_flag = True
                    break
            # ç®—æ³•5
            if not N_flag:
                big_log = await self.Algorithm_1_extend_1_run(page_name, new_pages[_index]["id"])
                small_log = await self.Algorithm_5_extend_1_run(page_name, new_pages[_index]["id"], "small")
                if not big_log:
                    big_uuid, big_log = await self.Algorithm_5_run(page_name, "big")
                    if big_uuid:
                        await self.update_notion_select(new_pages[_index]["id"], 1, big_uuid, page_name)
                if not small_log:
                    small_uuid, small_log = await self.Algorithm_5_run(page_name, "small")
                    if small_uuid:
                        await self.update_notion_select(new_pages[_index]["id"], 0, small_uuid, page_name)
                if small_log or big_log:
                    await self.update_notion_autolog(new_pages[_index]["id"], f"{big_log[0]}+{small_log[0]}", f"{big_log[1]}+{small_log[1]}", page_name)

    async def Algorithm_1_extend_1_run(self, page_name, page_id):
        """
        ç®—æ³•1çš„æ‰©å±•ç®—æ³•ï¼Œè¯†åˆ«äº‹ä»¶åç§°æ˜¯å¦æœ‰å†’å·çš„ç‰¹æ®Šå­—ç¬¦è¿›è¡Œåˆ‡å‰²ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºå¤§ç±»çš„åˆ¤åˆ«å…ƒç´ ï¼Œå¹¶åœ¨ç®—æ³•1æ•°æ®åº“ä¸­å¯»æ‰¾ç»“æžœ
        :param page_name:
        :param page_id:
        :return:
        """
        split_words = [_ for _ in [":", "ï¼š"] if _ in page_name]
        if len(split_words) > 0:
            page_name_0 = page_name.split(split_words[0])[0]
            Algorithm_1 = self.N_Algorithm_info[0]
            if page_name_0 in Algorithm_1["db"] and Algorithm_1["db"][page_name_0][1] > Algorithm_1["rate"]:
                _uuid_0 = Algorithm_1["db"][page_name_0][0].split(" ")[0]
                await self.update_notion_select(page_id, 1, _uuid_0, page_name)
                return [f"[1.1](big)", f"{page_name_0} {'%.2f'%Algorithm_1['db'][page_name_0][1]}"]
        return []

    async def Algorithm_5_extend_1_run(self, page_name, page_id, _type):
        """
        ç®—æ³•1çš„æ‰©å±•ç®—æ³•ï¼Œè¯†åˆ«äº‹ä»¶åç§°æ˜¯å¦æœ‰å†’å·çš„ç‰¹æ®Šå­—ç¬¦è¿›è¡Œåˆ‡å‰²ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºå¤§ç±»çš„åˆ¤åˆ«å…ƒç´ ï¼Œå¹¶åœ¨ç®—æ³•1æ•°æ®åº“ä¸­å¯»æ‰¾ç»“æžœ
        :param page_name:
        :param page_id:
        :param _type:
        :return:
        """
        split_words = [_ for _ in [":", "ï¼š"] if _ in page_name]
        if len(split_words) > 0:
            page_name_1 = page_name.split(split_words[0])[1]
            max_uuid, _log = await self.Algorithm_5_run(page_name_1, _type)
            if max_uuid:
                await self.update_notion_select(page_id, 0, max_uuid, page_name)
                _log[0] = f"[5.1]({_type})"
                return _log
        return []

    async def Algorithm_5_run(self, page_name, _type):
        # åˆ†è¯
        Algorithm_5 = self.S_Algorithm_info[0]
        words_list = Algorithm_5["key_generate"](page_name)
        hit_list = []
        for word in words_list:
            if word in Algorithm_5["db"][_type] and Algorithm_5["db"][_type][word][1] >= Algorithm_5["rate"]:
                hit_list.append(Algorithm_5["db"][_type][word])
        max_uuid = None
        max_num = 0
        max_key = None
        for _ in hit_list:
            if _[2] > max_num:
                max_num = _[2]
                max_uuid = _[0]
                max_key = _[-1]
        if max_uuid:
            return max_uuid, [f"{Algorithm_5['name']}({_type})", f"{max_key} {str(max_num)}"]
        return "", []

    @staticmethod
    def _sort(_list, _str=True):
        list(set(_list)).sort()
        if _str:
            return _list.__str__()
        else:
            return _list

    @staticmethod
    def _cut(sentence, withFlag=False):
        if not withFlag:
            _data = []
            [_data.append(_.word) for _ in p_seg.cut(sentence) if _.word.strip() not in special_word_list]
        else:
            _data = {}
            [_data.update({_.word: _.flag}) for _ in p_seg.cut(sentence) if _.word.strip() not in special_word_list]
        return _data

    async def run(self):
        scheduler = self.app.get_scheduler()
        await self.generate_db_path()
        await self.Algorithm_run()
        await self.calculate_cost_time()
        scheduler.add_job(self.calculate_cost_time, 'interval', seconds=600)
        scheduler.add_job(self.Algorithm_run, 'interval', seconds=600)
        scheduler.add_job(self.generate_db_path, 'cron', day_of_week=1, hour=11)


if __name__ == '__main__':
    pass
